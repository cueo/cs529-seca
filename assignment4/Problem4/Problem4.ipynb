{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PbUZth0zCHyp"
   },
   "outputs": [],
   "source": [
    "! pip install torchgan\n",
    "# Imports\n",
    "import keras\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Pytorch and Torchvision Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torch.optim import Adam\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "from torchgan.metrics import *\n",
    "\n",
    "# Torchgan Imports\n",
    "import torchgan\n",
    "from torchgan.models import *\n",
    "from torchgan.losses import *\n",
    "from torchgan.trainer import Trainer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VwamUjU3CHyu"
   },
   "source": [
    "## Loading the MINST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aLyDYPQ5CHyw"
   },
   "outputs": [],
   "source": [
    "dataset = dsets.MNIST(\n",
    "    root=\"./mnist\",\n",
    "    train=True,\n",
    "    transform=transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize((32, 32)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=(0.5,), std=(0.5,)),\n",
    "        ]\n",
    "    ),\n",
    "    download=True,\n",
    ")\n",
    "dataloader = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zWCN9WXDCHyy"
   },
   "outputs": [],
   "source": [
    "# Plot some of the training images\n",
    "real_batch = next(iter(dataloader))\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Training Images\")\n",
    "plt.imshow(\n",
    "    np.transpose(vutils.make_grid(real_batch[0][:64], padding=2, normalize=True).cpu(), (1, 2, 0))\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PtZlrTtqOueE"
   },
   "source": [
    "## Part 1 - DCGAN Network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9gjL16arCHyx"
   },
   "outputs": [],
   "source": [
    "# Setting up the DCGAN model \n",
    "dcgan_network = {\n",
    "    \"generator\": {None\n",
    "    },\n",
    "    \"discriminator\": {None\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XENqmmySCHyy"
   },
   "outputs": [],
   "source": [
    "# Defining the loss for DCGAN. The chosen Loss type is leasr square method.\n",
    "lsgan_losses = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UaSHPTL5P1Ch"
   },
   "source": [
    "Training the DCGAN network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LDzsJTloCHy0"
   },
   "outputs": [],
   "source": [
    "# Training the DCGAN network\n",
    "trainer = None\n",
    "trainer(dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cn-bSi25CHy2"
   },
   "outputs": [],
   "source": [
    "# Visual comparison of the real and the fake images. \n",
    "\n",
    "# Grab a batch of real images from the dataloader\n",
    "real_batch = next(iter(dataloader))\n",
    "device = torch.device(\"cuda:0\")\n",
    "# Plot the real images\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Real Images\")\n",
    "plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=5, normalize=True).cpu(),(1, 2, 0),))\n",
    "\n",
    "# Plot the fake images from the last epoch\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Fake Images\")\n",
    "plt.imshow(plt.imread(None))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SoluUqALP6PY"
   },
   "source": [
    "Accuracy of our trained DCGAN network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MthEGPdkDBL0"
   },
   "outputs": [],
   "source": [
    "# Accuracy of Descriminator on fake images \n",
    "# Generate 100 fake images for testing model accuracy\n",
    "\n",
    "# Randomly initialize the 100 images\n",
    "x = None\n",
    "\n",
    "# Pass the images to the generator to generate the random images\n",
    "out_gen = trainer.generator.forward(x)\n",
    "\n",
    "# Plot the random images generated\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(None)\n",
    "plt.title(\"Generated fake images\")\n",
    "plt.show()\n",
    "\n",
    "# Get the discriminator prediction of these images \n",
    "out_disc = trainer.discriminator.forward(out_gen)\n",
    "\n",
    "# Compute accuracy based on these predictions\n",
    "out_disc_np = out_disc.cpu().detach().numpy()\n",
    "condition = out_disc_np < 0.5\n",
    "accuracy = np.extract(None)\n",
    "accuracy_fake = None\n",
    "print(\"Accuracy of the model on fake images = \" ,  accuracy_fake)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cM5V1FfjHXca"
   },
   "outputs": [],
   "source": [
    "#Testing accuracy of benign inputs by choosing random samples from the actual dataset\n",
    "\n",
    "i = 0\n",
    "# Load batches of 64 images 100 times to get accuracy\n",
    "correct_detection = 0 \n",
    "while (i<100):\n",
    "  real_batch = next(iter(dataloader))\n",
    "  out_disc = trainer.discriminator.forward(real_batch[0].to(torch.device(\"cuda:0\")))\n",
    "  out_disc_np = out_disc.cpu().detach().numpy()\n",
    "  condition = out_disc_np > 0.5\n",
    "  accuracy = np.extract(None)\n",
    "  correct_detection = None\n",
    "  i = i+1\n",
    "accuracy_benign = None\n",
    "print (\"Accuracy of Descriminator on benign samples = \" , None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f7WQERWNTuyF"
   },
   "outputs": [],
   "source": [
    "# Total accuracy of the discriminator \n",
    "\n",
    "total_accuracy = None\n",
    "print (\"Accuracy of the Discriminator = \", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aCAx_OtKCHy4"
   },
   "outputs": [],
   "source": [
    "# Computing the accuracy of Generator.\n",
    "# Accuracy of the generator is computed using Inspection score which is a score of how accurately can human eyes identify the images as real.\n",
    "\n",
    "acc_generator = torchgan.metrics.ClassifierScore()\n",
    "acc_generator.classifier=trainer.generator\n",
    "score = None\n",
    "print(\"Inspector score for DCGAN: \" , None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ki_fNysDXGrM"
   },
   "source": [
    "## Part 2 - CGAN Network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tmfSLmDvPWc0"
   },
   "outputs": [],
   "source": [
    "# Setting up the CGAN model \n",
    "cgan_network = {\n",
    "    \"generator\": {None\n",
    "    },\n",
    "    \"discriminator\": {None\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "npDvc4pFYnmr"
   },
   "source": [
    "Training the CGAN network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LWjThYESCHy5"
   },
   "outputs": [],
   "source": [
    "# Training the CGAN network\n",
    "trainer_cgan = Trainer(None)\n",
    "trainer_cgan(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cHNd_LkUT4ja"
   },
   "outputs": [],
   "source": [
    "# Visual comparison of the real and the fake images.\n",
    "# Grab a batch of real images from the dataloader\n",
    "real_batch = next(iter(dataloader))\n",
    "# Plot the real images\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Real Images\")\n",
    "plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=5, normalize=True).cpu(),(1, 2, 0),))\n",
    "\n",
    "# Plot the fake images from the last epoch\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Fake Images\")\n",
    "plt.imshow(plt.imread(None))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pkZIEJKaY3FD"
   },
   "source": [
    "Accuracy of our trained CGAN network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-CBeZBSsNT3J"
   },
   "outputs": [],
   "source": [
    "# Accuracy of Descriminator on fake images \n",
    "# Generate 100 fake images for testing model accuracy\n",
    "\n",
    "# Randomly initialize the 100 images\n",
    "x = None\n",
    "# Generate labels for the images \n",
    "y = None\n",
    "\n",
    "# Pass the images to the generator to generate the random images\n",
    "out_gen = trainer.generator.forward(x, y)\n",
    "\n",
    "# Plot the random images generated\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(None)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Get the discriminator prediction of these images \n",
    "out_disc = trainer.discriminator.forward(out_gen, y)\n",
    "\n",
    "# Compute accuracy based on these predictions\n",
    "out_disc_np = out_disc.cpu().detach().numpy()\n",
    "condition = out_disc_np < 0.5\n",
    "accuracy = np.extract(condition, out_disc_np)\n",
    "accuracy_fake = accuracy.size\n",
    "print(\"Accuracy of the model on fake images = \" ,  accuracy_fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h1BywpHJN9Qh"
   },
   "outputs": [],
   "source": [
    "#Testing accuracy of benign inputs by choosing random samples from the actual dataset\n",
    "\n",
    "i = 0\n",
    "# Load batches of 64 images 100 times to get accuracy\n",
    "correct_detection = 0 \n",
    "while (i<100):\n",
    "  real_batch = next(iter(dataloader))\n",
    "  out_disc = trainer.discriminator.forward(real_batch[0].to(torch.device(\"cuda:0\")), real_batch[1])\n",
    "  out_disc_np = out_disc.cpu().detach().numpy()\n",
    "  condition = out_disc_np > 0.5\n",
    "  accuracy = np.extract(None)\n",
    "  correct_detection = None\n",
    "  i = i+1\n",
    "accuracy_benign = None\n",
    "print (\"Accuracy of Descriminator on benign samples = \" , None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7Wv64k6HamRt"
   },
   "outputs": [],
   "source": [
    "# Total accuracy of the discriminator \n",
    "\n",
    "total_accuracy = None\n",
    "print (\"Accuracy of the Discriminator = \", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W2rlf2PFXo1H"
   },
   "outputs": [],
   "source": [
    "# Computing the accuracy of Generator.\n",
    "# Accuracy of the generator is computed using Inspection score which is a score of how accurately can human eyes identify the images as real.\n",
    "\n",
    "acc_generator = torchgan.metrics.ClassifierScore()\n",
    "acc_generator.classifier=trainer_cgan.generator\n",
    "\n",
    "score = None\n",
    "print(\"Inspector score for DCGAN: \" , None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Problem.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
